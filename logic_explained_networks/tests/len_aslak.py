#!/usr/bin/env python

# -*- coding: utf-8 -*-
"""LEN_Aslak.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YHV5yqUJGzO0yb2Bf-XCl0hdb7QfWgob
"""


"""## Import LENs"""


import lens
import torch
import numpy as np
x = torch.rand([100, 85])
trainDataLabels_T = torch.randint(0, 2, (len(x),)).bool()
y=trainDataLabels_T
data = torch.utils.data.TensorDataset(x, y)
train_data, val_data, test_data = torch.utils.data.random_split(data, [80, 10, 10])
x_train, y_train = data[train_data.indices]
x_val, y_val = data[val_data.indices]
x_test, y_test = data[test_data.indices]
np.set_printoptions(threshold=np.inf)
print(y.numpy())

trainDataLabels_T.shape()

model = lens.models.XMuNN(n_classes=42, n_features=85,
                               hidden_neurons=[10], loss=torch.nn.CrossEntropyLoss())

#model = model.double()
model.fit(train_data, val_data, epochs=100, l_r=0.1)
test_acc = model.evaluate(test_data)
print("Test accuracy:", test_acc)

## get first order logic explanations for a specific target class
#unique_labels = torch.unique(trainDataLabels_T)
#np.set_printoptions(threshold=np.inf)
target_class =1
x_train = x_train.float()
model = model.float()
concept_names = ['x' + str(i) for i in range(1, 86)]
#y_train_t = torch.randint(0, 2, (len(x_train),)).bool()
formula = model.get_global_explanation(x_train, y_train, target_class, top_k_explanations=2, concept_names=concept_names)
print(f"{formula} <-> f{target_class}")
#np.set_printoptions(threshold=np.inf)
#true_count = torch.sum(y_train_t)

def plot_decision_bundaries(model, x, h=0.1, cmap='BrBG'):
    x1_min, x1_max = x[:, 0].min() - 1, x[:, 0].max() + 1
    x2_min, x2_max = x[:, 1].min() - 1, x[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h),
                           np.arange(x2_min, x2_max, h))
    xx = torch.FloatTensor(np.c_[xx1.ravel(), xx2.ravel()])
    Z = model(xx).detach().numpy()
    Z = Z.reshape(xx1.shape)
    plt.contourf(xx1, xx2, Z, alpha=0.2, cmap=cmap)
    return

x_train.shape

## compute explanation accuracy
exp_accuracy, _ = lens.logic.test_explanation(formula, target_class, x_test, y_test,
                                              concept_names=concept_names)
print("Logic Test Accuracy:", exp_accuracy)