{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabri/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from random_forest import XRandomForestClassifier\n",
    "\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import trange\n",
    "\n",
    "from lens.models.relu_nn import XReluNN\n",
    "from lens.models.psi_nn import XPsiNetwork\n",
    "from lens.models.tree import XDecisionTreeClassifier\n",
    "from lens.models.brl import XBRLClassifier\n",
    "from lens.models.logistic_regression import XLogisticRegressionClassifier\n",
    "from lens.models.deep_red import XDeepRedClassifier\n",
    "from lens.utils.base import set_seed, ClassifierNotTrainedError, IncompatibleClassifierError\n",
    "from lens.utils.metrics import Accuracy, F1Score\n",
    "from lens.models.mu_nn import XMuNN\n",
    "from lens.utils.datasets import ConceptToTaskDataset\n",
    "from lens.utils.data import get_splits_train_val_test\n",
    "from lens.logic.base import test_explanation\n",
    "from lens.logic.metrics import complexity, fidelity, formula_consistency\n",
    "from data import CUB200\n",
    "from data.download_cub import download_cub\n",
    "from experiments.CUB_200_2011.concept_extractor_cub import concept_extractor_cub\n",
    "\n",
    "results_dir = 'results/cub'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading CUB data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/CUB_200_2011/\n",
      "Dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"../data/CUB_200_2011/\"\n",
    "dataset_name = CUB200\n",
    "print(dataset_root)\n",
    "if not os.path.isdir(dataset_root):\n",
    "    download_cub(dataset_root)\n",
    "else:\n",
    "    print(\"Dataset already downloaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting concepts from images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts already extracted\n",
      "Concept names ['has_bill_shape_dagger' 'has_bill_shape_hooked_seabird'\n",
      " 'has_bill_shape_allpurpose' 'has_bill_shape_cone' 'has_wing_color_brown'\n",
      " 'has_wing_color_grey' 'has_wing_color_yellow' 'has_wing_color_black'\n",
      " 'has_wing_color_white' 'has_wing_color_buff' 'has_upperparts_color_brown'\n",
      " 'has_upperparts_color_grey' 'has_upperparts_color_yellow'\n",
      " 'has_upperparts_color_black' 'has_upperparts_color_white'\n",
      " 'has_upperparts_color_buff' 'has_underparts_color_brown'\n",
      " 'has_underparts_color_grey' 'has_underparts_color_yellow'\n",
      " 'has_underparts_color_black' 'has_underparts_color_white'\n",
      " 'has_underparts_color_buff' 'has_breast_pattern_solid'\n",
      " 'has_breast_pattern_striped' 'has_breast_pattern_multicolored'\n",
      " 'has_back_color_brown' 'has_back_color_grey' 'has_back_color_yellow'\n",
      " 'has_back_color_black' 'has_back_color_white' 'has_back_color_buff'\n",
      " 'has_tail_shape_notched_tail' 'has_upper_tail_color_brown'\n",
      " 'has_upper_tail_color_grey' 'has_upper_tail_color_black'\n",
      " 'has_upper_tail_color_white' 'has_upper_tail_color_buff'\n",
      " 'has_head_pattern_plain' 'has_head_pattern_capped'\n",
      " 'has_breast_color_brown' 'has_breast_color_grey'\n",
      " 'has_breast_color_yellow' 'has_breast_color_black'\n",
      " 'has_breast_color_white' 'has_breast_color_buff' 'has_throat_color_grey'\n",
      " 'has_throat_color_yellow' 'has_throat_color_black'\n",
      " 'has_throat_color_white' 'has_eye_color_black'\n",
      " 'has_bill_length_about_the_same_as_head'\n",
      " 'has_bill_length_shorter_than_head' 'has_forehead_color_blue'\n",
      " 'has_forehead_color_brown' 'has_forehead_color_grey'\n",
      " 'has_forehead_color_yellow' 'has_forehead_color_black'\n",
      " 'has_forehead_color_white' 'has_forehead_color_red'\n",
      " 'has_under_tail_color_brown' 'has_under_tail_color_grey'\n",
      " 'has_under_tail_color_yellow' 'has_under_tail_color_black'\n",
      " 'has_under_tail_color_white' 'has_under_tail_color_buff'\n",
      " 'has_nape_color_blue' 'has_nape_color_brown' 'has_nape_color_grey'\n",
      " 'has_nape_color_yellow' 'has_nape_color_black' 'has_nape_color_white'\n",
      " 'has_nape_color_buff' 'has_belly_color_grey' 'has_belly_color_yellow'\n",
      " 'has_belly_color_black' 'has_belly_color_white' 'has_belly_color_buff'\n",
      " 'has_wing_shape_roundedwings' 'has_size_small_5__9_in'\n",
      " 'has_size_medium_9__16_in' 'has_size_very_small_3__5_in'\n",
      " 'has_shape_perchinglike' 'has_back_pattern_solid'\n",
      " 'has_back_pattern_striped' 'has_back_pattern_multicolored'\n",
      " 'has_tail_pattern_solid' 'has_tail_pattern_multicolored'\n",
      " 'has_belly_pattern_solid' 'has_primary_color_brown'\n",
      " 'has_primary_color_grey' 'has_primary_color_yellow'\n",
      " 'has_primary_color_black' 'has_primary_color_white'\n",
      " 'has_primary_color_buff' 'has_leg_color_grey' 'has_leg_color_black'\n",
      " 'has_leg_color_buff' 'has_bill_color_grey' 'has_bill_color_black'\n",
      " 'has_crown_color_blue' 'has_crown_color_brown' 'has_crown_color_grey'\n",
      " 'has_crown_color_yellow' 'has_crown_color_black' 'has_crown_color_white'\n",
      " 'has_wing_pattern_solid' 'has_wing_pattern_striped'\n",
      " 'has_wing_pattern_multicolored']\n",
      "Number of features 108\n",
      "Class names ['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird', '011.Rusty_Blackbird', '012.Yellow_headed_Blackbird', '013.Bobolink', '014.Indigo_Bunting', '015.Lazuli_Bunting', '016.Painted_Bunting', '017.Cardinal', '018.Spotted_Catbird', '019.Gray_Catbird', '020.Yellow_breasted_Chat', '021.Eastern_Towhee', '022.Chuck_will_Widow', '023.Brandt_Cormorant', '024.Red_faced_Cormorant', '025.Pelagic_Cormorant', '026.Bronzed_Cowbird', '027.Shiny_Cowbird', '028.Brown_Creeper', '029.American_Crow', '030.Fish_Crow', '031.Black_billed_Cuckoo', '032.Mangrove_Cuckoo', '033.Yellow_billed_Cuckoo', '034.Gray_crowned_Rosy_Finch', '035.Purple_Finch', '036.Northern_Flicker', '037.Acadian_Flycatcher', '038.Great_Crested_Flycatcher', '039.Least_Flycatcher', '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher', '042.Vermilion_Flycatcher', '043.Yellow_bellied_Flycatcher', '044.Frigatebird', '045.Northern_Fulmar', '046.Gadwall', '047.American_Goldfinch', '048.European_Goldfinch', '049.Boat_tailed_Grackle', '050.Eared_Grebe', '051.Horned_Grebe', '052.Pied_billed_Grebe', '053.Western_Grebe', '054.Blue_Grosbeak', '055.Evening_Grosbeak', '056.Pine_Grosbeak', '057.Rose_breasted_Grosbeak', '058.Pigeon_Guillemot', '059.California_Gull', '060.Glaucous_winged_Gull', '061.Heermann_Gull', '062.Herring_Gull', '063.Ivory_Gull', '064.Ring_billed_Gull', '065.Slaty_backed_Gull', '066.Western_Gull', '067.Anna_Hummingbird', '068.Ruby_throated_Hummingbird', '069.Rufous_Hummingbird', '070.Green_Violetear', '071.Long_tailed_Jaeger', '072.Pomarine_Jaeger', '073.Blue_Jay', '074.Florida_Jay', '075.Green_Jay', '076.Dark_eyed_Junco', '077.Tropical_Kingbird', '078.Gray_Kingbird', '079.Belted_Kingfisher', '080.Green_Kingfisher', '081.Pied_Kingfisher', '082.Ringed_Kingfisher', '083.White_breasted_Kingfisher', '084.Red_legged_Kittiwake', '085.Horned_Lark', '086.Pacific_Loon', '087.Mallard', '088.Western_Meadowlark', '089.Hooded_Merganser', '090.Red_breasted_Merganser', '091.Mockingbird', '092.Nighthawk', '093.Clark_Nutcracker', '094.White_breasted_Nuthatch', '095.Baltimore_Oriole', '096.Hooded_Oriole', '097.Orchard_Oriole', '098.Scott_Oriole', '099.Ovenbird', '100.Brown_Pelican', '101.White_Pelican', '102.Western_Wood_Pewee', '103.Sayornis', '104.American_Pipit', '105.Whip_poor_Will', '106.Horned_Puffin', '107.Common_Raven', '108.White_necked_Raven', '109.American_Redstart', '110.Geococcyx', '111.Loggerhead_Shrike', '112.Great_Grey_Shrike', '113.Baird_Sparrow', '114.Black_throated_Sparrow', '115.Brewer_Sparrow', '116.Chipping_Sparrow', '117.Clay_colored_Sparrow', '118.House_Sparrow', '119.Field_Sparrow', '120.Fox_Sparrow', '121.Grasshopper_Sparrow', '122.Harris_Sparrow', '123.Henslow_Sparrow', '124.Le_Conte_Sparrow', '125.Lincoln_Sparrow', '126.Nelson_Sharp_tailed_Sparrow', '127.Savannah_Sparrow', '128.Seaside_Sparrow', '129.Song_Sparrow', '130.Tree_Sparrow', '131.Vesper_Sparrow', '132.White_crowned_Sparrow', '133.White_throated_Sparrow', '134.Cape_Glossy_Starling', '135.Bank_Swallow', '136.Barn_Swallow', '137.Cliff_Swallow', '138.Tree_Swallow', '139.Scarlet_Tanager', '140.Summer_Tanager', '141.Artic_Tern', '142.Black_Tern', '143.Caspian_Tern', '144.Common_Tern', '145.Elegant_Tern', '146.Forsters_Tern', '147.Least_Tern', '148.Green_tailed_Towhee', '149.Brown_Thrasher', '150.Sage_Thrasher', '151.Black_capped_Vireo', '152.Blue_headed_Vireo', '153.Philadelphia_Vireo', '154.Red_eyed_Vireo', '155.Warbling_Vireo', '156.White_eyed_Vireo', '157.Yellow_throated_Vireo', '158.Bay_breasted_Warbler', '159.Black_and_white_Warbler', '160.Black_throated_Blue_Warbler', '161.Blue_winged_Warbler', '162.Canada_Warbler', '163.Cape_May_Warbler', '164.Cerulean_Warbler', '165.Chestnut_sided_Warbler', '166.Golden_winged_Warbler', '167.Hooded_Warbler', '168.Kentucky_Warbler', '169.Magnolia_Warbler', '170.Mourning_Warbler', '171.Myrtle_Warbler', '172.Nashville_Warbler', '173.Orange_crowned_Warbler', '174.Palm_Warbler', '175.Pine_Warbler', '176.Prairie_Warbler', '177.Prothonotary_Warbler', '178.Swainson_Warbler', '179.Tennessee_Warbler', '180.Wilson_Warbler', '181.Worm_eating_Warbler', '182.Yellow_Warbler', '183.Northern_Waterthrush', '184.Louisiana_Waterthrush', '185.Bohemian_Waxwing', '186.Cedar_Waxwing', '187.American_Three_toed_Woodpecker', '188.Pileated_Woodpecker', '189.Red_bellied_Woodpecker', '190.Red_cockaded_Woodpecker', '191.Red_headed_Woodpecker', '192.Downy_Woodpecker', '193.Bewick_Wren', '194.Cactus_Wren', '195.Carolina_Wren', '196.House_Wren', '197.Marsh_Wren', '198.Rock_Wren', '199.Winter_Wren', '200.Common_Yellowthroat']\n",
      "Number of classes 200\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(os.path.join(dataset_root, f\"{dataset_name}_predictions.npy\")):\n",
    "    concept_extractor_cub(dataset_root)\n",
    "else:\n",
    "    print(\"Concepts already extracted\")\n",
    "dataset = ConceptToTaskDataset(dataset_root, dataset_name=dataset_name, predictions=True)\n",
    "concept_names = dataset.attribute_names\n",
    "print(\"Concept names\", concept_names)\n",
    "n_features = dataset.n_attributes\n",
    "print(\"Number of features\", n_features)\n",
    "class_names = dataset.classes\n",
    "print(\"Class names\", class_names)\n",
    "n_classes = dataset.n_classes\n",
    "print(\"Number of classes\", n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define loss, metrics and methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods ['RandomForest']\n"
     ]
    }
   ],
   "source": [
    "loss = CrossEntropyLoss()\n",
    "metric = Accuracy()\n",
    "expl_metric = F1Score()\n",
    "method_list = ['RandomForest']  #['DTree', 'BRL', 'Psi', 'Relu', 'General']  # 'DeepRed']\n",
    "print(\"Methods\", method_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting training hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "n_processes = 1\n",
    "timeout = 6 * 60 * 60  # 6 h timeout\n",
    "l_r = 1e-3\n",
    "lr_scheduler = False\n",
    "top_k_explanations = None\n",
    "simplify = True\n",
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds [0, 1, 2, 3, 4]\n",
      "[    0     1     3 ... 11785 11786 11787]\n",
      "Training results/cub\\RandomForest_0 classifier...\n",
      "Model results/cub\\RandomForest_0 already trained\n",
      "Test model accuracy 92.13863060016905\n",
      "Explanation time 25.553309202194214\n",
      "Explanation accuracy mean 0.0\n",
      "Explanation fidelity mean 0.0\n",
      "Explanation complexity mean 0.0\n",
      "[    0     1     2 ... 11785 11786 11787]\n",
      "Training results/cub\\RandomForest_1 classifier...\n",
      "Model results/cub\\RandomForest_1 already trained\n",
      "Test model accuracy 92.05409974640743\n",
      "Explanation time 21.45211935043335\n",
      "Explanation accuracy mean 0.0\n",
      "Explanation fidelity mean 0.0\n",
      "Explanation complexity mean 0.0\n",
      "[    0     1     2 ... 11785 11786 11787]\n",
      "Training results/cub\\RandomForest_2 classifier...\n",
      "Model results/cub\\RandomForest_2 already trained\n",
      "Test model accuracy 90.4480135249366\n",
      "Explanation time 23.347834825515747\n",
      "Explanation accuracy mean 0.0\n",
      "Explanation fidelity mean 0.0\n",
      "Explanation complexity mean 0.0\n",
      "[    0     1     2 ... 11784 11786 11787]\n",
      "Training results/cub\\RandomForest_3 classifier...\n",
      "Model results/cub\\RandomForest_3 already trained\n",
      "Test model accuracy 92.39222316145394\n",
      "Explanation time 23.780805110931396\n",
      "Explanation accuracy mean 0.0\n",
      "Explanation fidelity mean 0.0\n",
      "Explanation complexity mean 0.0\n",
      "[    0     1     2 ... 11783 11785 11786]\n",
      "Training results/cub\\RandomForest_4 classifier...\n",
      "Model results/cub\\RandomForest_4 already trained\n",
      "Test model accuracy 92.39222316145394\n",
      "Explanation time 22.21117854118347\n",
      "Explanation accuracy mean 0.0\n",
      "Explanation fidelity mean 0.0\n",
      "Explanation complexity mean 0.0\n",
      "Consistency of explanations: 1.0000\n",
      "         method  split explanation  model_accuracy  explanation_accuracy  \\\n",
      "0  RandomForest      0                   92.138631                   0.0   \n",
      "1  RandomForest      1                   92.054100                   0.0   \n",
      "2  RandomForest      2                   90.448014                   0.0   \n",
      "3  RandomForest      3                   92.392223                   0.0   \n",
      "4  RandomForest      4                   92.392223                   0.0   \n",
      "\n",
      "   explanation_fidelity  explanation_complexity  explanation_consistency  \\\n",
      "0                   0.0                     0.0                      1.0   \n",
      "1                   0.0                     0.0                      1.0   \n",
      "2                   0.0                     0.0                      1.0   \n",
      "3                   0.0                     0.0                      1.0   \n",
      "4                   0.0                     0.0                      1.0   \n",
      "\n",
      "   elapsed_time  \n",
      "0     25.553309  \n",
      "1     21.452119  \n",
      "2     23.347835  \n",
      "3     23.780805  \n",
      "4     22.211179  \n"
     ]
    }
   ],
   "source": [
    "for method in method_list:\n",
    "\n",
    "    methods = []\n",
    "    splits = []\n",
    "    model_explanations = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    elapsed_times = []\n",
    "    explanation_fidelities = []\n",
    "    explanation_complexities = []\n",
    "\n",
    "    seeds = [*range(5)] if method != \"BRL\" else [*range(3)]\n",
    "    print(\"Seeds\", seeds)\n",
    "\n",
    "    for seed in seeds:\n",
    "        set_seed(seed)\n",
    "        name = os.path.join(results_dir, f\"{method}_{seed}\")\n",
    "\n",
    "        train_data, val_data, test_data = get_splits_train_val_test(dataset, load=False)\n",
    "        x_train = torch.tensor(dataset.attributes[train_data.indices])\n",
    "        y_train = torch.tensor(dataset.targets[train_data.indices])\n",
    "        x_val = torch.tensor(dataset.attributes[val_data.indices])\n",
    "        y_val = torch.tensor(dataset.targets[val_data.indices])\n",
    "        x_test = torch.tensor(dataset.attributes[test_data.indices])\n",
    "        y_test = torch.tensor(dataset.targets[test_data.indices])\n",
    "        print(train_data.indices)\n",
    "\n",
    "        # Setting device\n",
    "        print(f\"Training {name} classifier...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if method == 'DTree':\n",
    "            max_depth = 30\n",
    "            name += f\"_{max_depth}\"\n",
    "            model = XDecisionTreeClassifier(name=name, n_classes=n_classes,\n",
    "                                            n_features=n_features, max_depth=max_depth)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, metric=metric, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(i, concept_names)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test, metric=expl_metric,\n",
    "                                                                 concept_names=concept_names, inequalities=True)\n",
    "                exp_fidelity = 100\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'BRL':\n",
    "            train_sample_rate = 1.0\n",
    "            model = XBRLClassifier(name=name, n_classes=n_classes, n_features=n_features, n_processes=n_processes,\n",
    "                                   feature_names=concept_names, class_names=class_names, discretize=True)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, metric=metric, train_sample_rate=train_sample_rate, verbose=False, eval=False)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(i, concept_names)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test, metric=expl_metric,\n",
    "                                                                 concept_names=concept_names)\n",
    "                exp_fidelity = 100\n",
    "                explanation_complexity = complexity(explanation, to_dnf=True)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'DeepRed':\n",
    "            train_idx = train_data.indices\n",
    "            test_idx = test_data.indices\n",
    "            train_sample_rate = 0.05\n",
    "            model = XDeepRedClassifier(n_classes, n_features, name=name)\n",
    "            model.prepare_data(dataset, dataset_name, seed, train_idx, test_idx, train_sample_rate)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(epochs=epochs, seed=seed, metric=metric)\n",
    "            outputs, labels = model.predict(train=False, device=device)\n",
    "            accuracy = model.evaluate(train=False, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            print(\"Extracting rules...\")\n",
    "            t = time.time()\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(i, concept_names, simplify=simplify)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric,\n",
    "                                                                 concept_names=concept_names, inequalities=True)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "                print(f\"{i + 1}/{len(dataset.classes)} Rules extracted. Time {time.time() - t}\")\n",
    "            # To restore the original folder\n",
    "\n",
    "        elif method == 'Psi':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-4\n",
    "            hidden_neurons = [10]  # [50, 20, 10]\n",
    "            fan_in = 4\n",
    "            lr_psi = 1e-2\n",
    "            print(\"L1 weight\", l1_weight)\n",
    "            print(\"Hidden neurons\", hidden_neurons)\n",
    "            print(\"Fan in\", fan_in)\n",
    "            model = XPsiNetwork(n_classes, n_features, hidden_neurons, loss, l1_weight, name=name, fan_in=fan_in)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=lr_psi, verbose=True,\n",
    "                          metric=metric, lr_scheduler=lr_scheduler, device=device, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes):\n",
    "                explanation = model.get_global_explanation(i, concept_names, simplify=simplify, x_train=x_train)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric, concept_names=concept_names)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation, to_dnf=True)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'General':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-4\n",
    "            hidden_neurons = [20]\n",
    "            print(\"L1 weight\", l1_weight)\n",
    "            print(\"Hidden neurons\", hidden_neurons)\n",
    "            model = XMuNN(n_classes=n_classes, n_features=n_features, hidden_neurons=hidden_neurons,\n",
    "                               loss=loss, name=name, l1_weight=l1_weight, fan_in=10, )\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=l_r, metric=metric,\n",
    "                          lr_scheduler=lr_scheduler, device=device, save=True, verbose=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(x_train, y_train, i, top_k_explanations=top_k_explanations,\n",
    "                                                           concept_names=concept_names, simplify=simplify,\n",
    "                                                           metric=expl_metric, x_val=x_val, y_val=y_val)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric, concept_names=concept_names)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'Relu':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-7\n",
    "            hidden_neurons = [300, 200]\n",
    "            dropout_rate = 0.\n",
    "            print(\"l1 weight\", l1_weight)\n",
    "            print(\"hidden neurons\", hidden_neurons)\n",
    "            model = XReluNN(n_classes=n_classes, n_features=n_features, name=name, dropout_rate=dropout_rate,\n",
    "                            hidden_neurons=hidden_neurons, loss=loss, l1_weight=l1_weight)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=l_r, verbose=True,\n",
    "                          metric=metric, lr_scheduler=lr_scheduler, device=device, save=True)\n",
    "            outputs, labels = model.predict(test_data, device=device)\n",
    "            accuracy = model.evaluate(test_data, metric=metric, outputs=outputs, labels=labels)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [], [], [], []\n",
    "            for i in trange(n_classes, desc=f\"{method} extracting explanations\"):\n",
    "                explanation = model.get_global_explanation(x_train, y_train, i,\n",
    "                                                           top_k_explanations=top_k_explanations,\n",
    "                                                           concept_names=concept_names,\n",
    "                                                           metric=expl_metric, x_val=x_val, y_val=y_val)\n",
    "                exp_accuracy, exp_predictions = test_explanation(explanation, i, x_test, y_test,\n",
    "                                                                 metric=expl_metric, concept_names=concept_names)\n",
    "                exp_predictions = torch.as_tensor(exp_predictions)\n",
    "                class_output = torch.as_tensor(outputs.argmax(dim=1) == i)\n",
    "                exp_fidelity = fidelity(exp_predictions, class_output, expl_metric)\n",
    "                explanation_complexity = complexity(explanation)\n",
    "                explanations.append(explanation), exp_accuracies.append(exp_accuracy)\n",
    "                exp_fidelities.append(exp_fidelity), exp_complexities.append(explanation_complexity)\n",
    "\n",
    "        elif method == 'RandomForest':\n",
    "            set_seed(seed)\n",
    "            model = XRandomForestClassifier(name=name, n_classes=n_classes,\n",
    "                                            n_features=n_features)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                model.fit(train_data, val_data, epochs=epochs, l_r=l_r, metric=metric,\n",
    "                          lr_scheduler=lr_scheduler, device=device, save=True, verbose=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            explanations, exp_accuracies, exp_fidelities, exp_complexities = [\"\"], [0], [0], [0]\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{method} not implemented\")\n",
    "\n",
    "        if model.time is None:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            # In DeepRed and BRL the training is parallelized to speed up operation\n",
    "            if method == \"BRL\":\n",
    "                elapsed_time = elapsed_time * n_processes\n",
    "            model.time = elapsed_time\n",
    "            # To save the elapsed time and the explanations\n",
    "            model.save(device)\n",
    "        else:\n",
    "            elapsed_time = model.time\n",
    "\n",
    "        # Restore original folder\n",
    "        if method == \"DeepRed\":\n",
    "            model.finish()\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(seed)\n",
    "        model_explanations.append(explanations[0])\n",
    "        model_accuracies.append(accuracy)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "        explanation_accuracies.append(np.mean(exp_accuracies))\n",
    "        explanation_fidelities.append(np.mean(exp_fidelities))\n",
    "        explanation_complexities.append(np.mean(exp_complexities))\n",
    "        print(\"Test model accuracy\", accuracy)\n",
    "        print(\"Explanation time\", elapsed_time)\n",
    "        print(\"Explanation accuracy mean\", np.mean(exp_accuracies))\n",
    "        print(\"Explanation fidelity mean\", np.mean(exp_fidelities))\n",
    "        print(\"Explanation complexity mean\", np.mean(exp_complexities))\n",
    "\n",
    "    explanation_consistency = formula_consistency(model_explanations)\n",
    "    print(f'Consistency of explanations: {explanation_consistency:.4f}')\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': model_explanations,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_fidelity': explanation_fidelities,\n",
    "        'explanation_complexity': explanation_complexities,\n",
    "        'explanation_consistency': [explanation_consistency] * len(seeds),\n",
    "        'elapsed_time': elapsed_times,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model_accuracy_mean  explanation_accuracy_mean  \\\n",
      "RandomForest            91.885038                        0.0   \n",
      "\n",
      "              explanation_fidelity_mean  explanation_complexity_mean  \\\n",
      "RandomForest                        0.0                          0.0   \n",
      "\n",
      "              elapsed_time_mean  explanation_consistency_mean  \\\n",
      "RandomForest          23.269049                           1.0   \n",
      "\n",
      "              model_accuracy_sem  explanation_accuracy_sem  \\\n",
      "RandomForest            0.365541                       0.0   \n",
      "\n",
      "              explanation_fidelity_sem  explanation_complexity_sem  \\\n",
      "RandomForest                       0.0                         0.0   \n",
      "\n",
      "              elapsed_time_sem  explanation_consistency_sem  \n",
      "RandomForest          0.703785                          0.0  \n"
     ]
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_fidelity', 'explanation_complexity', 'elapsed_time',\n",
    "        'explanation_consistency']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "results_df = {}\n",
    "summaries = {}\n",
    "for m in method_list:\n",
    "    results_df[m] = pd.read_csv(os.path.join(results_dir, f\"results_{m}.csv\"))\n",
    "    df_mean = results_df[m][cols].mean()\n",
    "    df_sem = results_df[m][cols].sem()\n",
    "    df_mean.columns = mean_cols\n",
    "    df_sem.columns = sem_cols\n",
    "    summaries[m] = pd.concat([df_mean, df_sem])\n",
    "    summaries[m].name = m\n",
    "\n",
    "results_df = pd.concat([results_df[method] for method in method_list])\n",
    "results_df.to_csv(os.path.join(results_dir, f'results_{method_list}.csv'))\n",
    "\n",
    "summary = pd.concat([summaries[method] for method in method_list], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary.to_csv(os.path.join(results_dir, f'summary_{method_list}.csv'))\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}