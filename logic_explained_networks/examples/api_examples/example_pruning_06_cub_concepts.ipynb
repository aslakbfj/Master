{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lens.nn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlens\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrelu_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_reduced_model, prune_features\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlens\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logic\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlens\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\__init__.py:2\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logic\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\models\\__init__.py:1\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpsi_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m XPsiNetwork\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrelu_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m XReluNN\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeneral_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m XMuNN\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\models\\psi_nn.py:8\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NotAvailableError\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpsi_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m prune_equal_fanin\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlogic\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpsi_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generate_fol_explanations, generate_fol_explanations_from_data\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseClassifier, BaseXModel\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mPsiNetwork\u001B[39;00m(BaseClassifier, BaseXModel):\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\logic\\__init__.py:4\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpsi_nn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generate_fol_explanations\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m replace_names, test_explanation\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m explain_class\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m concept_consistency, formula_consistency, predictions, fidelity, complexity\n\u001B[0;32m      7\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexplain_class\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexplain_global\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcomplexity\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     20\u001B[0m ]\n",
      "File \u001B[1;32m~\\Documents\\Scuola\\3_Dottorato\\Codice\\LENs\\lens\\logic\\layer.py:11\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m simplify_logic\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m replace_names, test_explanation\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m XLogic  \u001B[38;5;66;03m# , XLogicConv2d\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_categorical\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexplain_class\u001B[39m(model: torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule, x: torch\u001B[38;5;241m.\u001B[39mTensor, y: torch\u001B[38;5;241m.\u001B[39mTensor, binary: \u001B[38;5;28mbool\u001B[39m,\n\u001B[0;32m     16\u001B[0m                   target_class: \u001B[38;5;28mint\u001B[39m, simplify: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, topk_explanations: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m     17\u001B[0m                   concept_names: List \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'lens.nn'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lens.utils.relu_nn import get_reduced_model, prune_features\n",
    "from lens import logic\n",
    "import lens\n",
    "from lens.utils.datasets import ConceptToTaskDataset\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ConceptToTaskDataset(\"../data/CUB_200_2011\", predictions=True)\n",
    "\n",
    "X = dataset.attributes\n",
    "y = np.asarray(dataset.targets)\n",
    "\n",
    "concept_names = dataset.attribute_names\n",
    "concept_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = sklearn.preprocessing.OneHotEncoder(sparse=False).fit_transform(y.reshape(-1, 1))\n",
    "X = sklearn.preprocessing.MinMaxScaler((0, 1)).fit_transform(X)\n",
    "print(f'X shape: {X.shape}\\nClasses: {np.unique(y)}')\n",
    "print(f'X max: {X.max()} X min {X.min()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(f'X shape: {X.shape}\\nY shape: {y.shape}')\n",
    "print(f'X_test shape: {X_test.shape}\\nY_test shape: {y_test.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = torch.tensor(X, dtype=torch.float)\n",
    "print(x_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = torch.zeros((y.shape[0], y.shape[1]), dtype=torch.float)\n",
    "y_train = torch.tensor(y, dtype=torch.float)\n",
    "x_test = x_train\n",
    "n_classes = y_train.size(1)\n",
    "print(n_classes)\n",
    "print(y_train)\n",
    "y_train.sum(dim=0)\n",
    "\n",
    "# torch.cuda.set_device(0)\n",
    "n_classes = y_train.shape[1]\n",
    "device = torch.device(\"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.argmax(dim=1).to(torch.long).to(device)\n",
    "loss_form = torch.nn.NLLLoss() # CrossEntropyLoss()\n",
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "dimensions = [200, 200]\n",
    "layers = [\n",
    "    torch.nn.Linear(x_train.size(1), dimensions[0] * n_classes),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    lens.nn.XLinear(dimensions[0], dimensions[1], n_classes),\n",
    "    torch.nn.Softmax(),\n",
    "]\n",
    "model = torch.nn.Sequential(*layers)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "model.train()\n",
    "need_pruning = True\n",
    "for epoch in range(3000):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # forward pass\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train).squeeze()\n",
    "    y_train = y_train.to(torch.long)\n",
    "    # print(\"x_train\", x_train.shape, x_train.dtype)\n",
    "    # print(\"y_pred\", y_pred.shape, y_pred.dtype)\n",
    "    # print(\"y_train\", y_train.shape, y_train.dtype)\n",
    "    # Compute Loss\n",
    "    loss = loss_form(torch.log(y_pred), y_train)\n",
    "\n",
    "    for module in model.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            loss += 1e-8 * torch.norm(module.weight, 1)\n",
    "            break\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch > 1500 and need_pruning:\n",
    "        prune_features(model, n_classes, device=device)\n",
    "        need_pruning = False\n",
    "\n",
    "    # compute accuracy\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "        y_train_d = y_train # torch.argmax(y_train, dim=1)\n",
    "        accuracy = y_pred_d.eq(y_train_d).sum().item() / y_train.size(0) * 100.\n",
    "        print(f'Epoch: {epoch + 1} train accuracy: {accuracy:.2f} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Local explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "outputs = []\n",
    "for i, (xin, yin) in enumerate(zip(x_train, y_train)):\n",
    "    model_reduced = get_reduced_model(model, xin)\n",
    "    for module in model_reduced.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            wa = module.weight.detach().numpy()\n",
    "            ba = module.bias.detach().numpy()\n",
    "            break\n",
    "    output = model_reduced(xin)\n",
    "\n",
    "    pred_class = torch.argmax(output)\n",
    "    true_class = torch.argmax(y_train[i])\n",
    "\n",
    "    # generate local explanation only if the prediction is correct\n",
    "    if pred_class.eq(true_class):\n",
    "        local_explanation = logic.relu_nn.explain_local(model, x_train, y_train, xin)\n",
    "        print(f'Input {(i + 1)}')\n",
    "        print(f'\\tx={xin.detach().numpy()}')\n",
    "        print(f'\\ty={output.detach().numpy()}, y_label={yin}')\n",
    "        print(f'\\tw={wa}')\n",
    "        print(f'\\tb={ba}')\n",
    "        print(f'\\tExplanation: {local_explanation}')\n",
    "        print()\n",
    "        xin = xin.reshape(8, 8)\n",
    "        plt.figure(1, figsize=(3, 3))\n",
    "        plt.imshow(xin, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.show()\n",
    "#         wa = wa.reshape(8, 8)\n",
    "#         plt.figure(1, figsize=(3, 3))\n",
    "#         plt.imshow(wa * xin.numpy(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "#         plt.show()\n",
    "\n",
    "    outputs.append(output)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% md\n",
    "\n",
    "# Combine local explanations\n",
    "\n",
    "# %%\n",
    "counters = []\n",
    "from sklearn.metrics import f1_score\n",
    "y_train_d = torch.argmax(y_train, dim=1)\n",
    "for target_class in range(n_classes):\n",
    "    global_explanation, predictions, counter = logic.combine_local_explanations(model, x_train, y_train,\n",
    "                                                                              topk_explanations=10,\n",
    "                                                                              target_class=target_class,\n",
    "                                                                              concept_names=concept_names)\n",
    "\n",
    "    y2 = torch.argmax(y_train, dim=1) == target_class\n",
    "    accuracy = sum(predictions == y2.detach().numpy().squeeze()) / len(predictions)\n",
    "    f1 = f1_score(y_train[:, target_class], predictions)\n",
    "    print(f'Class {target_class} - Global explanation: \"{global_explanation}\" - Accuracy: {accuracy:.4f} - F1: {f1:.4f}')\n",
    "    counters.append(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, counter in enumerate(counters):\n",
    "    for j, values in enumerate(counter.items()):\n",
    "        print(i, j, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "y_pred = model(torch.Tensor(X_test)).argmax(dim=1).detach().numpy()\n",
    "y_test = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Accuracy: {accuracy:.2f}.\\nF1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier(max_depth=30)\n",
    "X_bool = X > 0.5\n",
    "tree_model.fit(X, y_train_d.cpu().numpy())\n",
    "X_test_bool = X_test > 0.5\n",
    "\n",
    "y_pred = tree_model.predict(X)\n",
    "accuracy = accuracy_score(y_train.cpu().numpy(), y_pred)\n",
    "f1 = f1_score(y_train.cpu().numpy(), y_pred, average='macro')\n",
    "print(f\"Accuracy: {accuracy:.2f}.\\nF1: {f1:.2f}\")\n",
    "\n",
    "y_pred = tree_model.predict(X_test)\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "f1 = f1_score(np.argmax(y_test, axis=1), y_pred, average='macro')\n",
    "print(f\"Accuracy: {accuracy:.2f}.\\nF1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.tree.plot_tree(tree_model)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}