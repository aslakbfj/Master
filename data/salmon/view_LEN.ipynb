{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \"\"\"\n",
    "        :param num_cnns: int, number of independent cnn units\n",
    "        :param input_length: int, input sequence length\n",
    "        :param num_classes: int, number of outputs\n",
    "        :param filter_size: int, size of the unit's filter, default=19\n",
    "        :param num_fc: int, number of FC layers in the unit, default=2\n",
    "        :param pool_size: int, size of the unit's maxpooling layer, default=7\n",
    "        :param pool_stride: int, stride of the unit's maxpooling layer, default=7\n",
    "        :param weight_path: string, path to the file with model weights\n",
    "        \"\"\"\n",
    "import sys\n",
    "sys.path.append('C:/Users/aslak/Master/Github_first/Master/explainn/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExplaiNN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    The ExplaiNN model (PMID: 37370113)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_cnns, input_length, num_classes, filter_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m, num_fc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, pool_stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m      6\u001b[0m                  weight_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class ExplaiNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The ExplaiNN model (PMID: 37370113)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_cnns, input_length, num_classes, filter_size=19, num_fc=2, pool_size=7, pool_stride=7,\n",
    "                 weight_path=None):\n",
    "        \"\"\"\n",
    "        :param num_cnns: int, number of independent cnn units\n",
    "        :param input_length: int, input sequence length\n",
    "        :param num_classes: int, number of outputs\n",
    "        :param filter_size: int, size of the unit's filter, default=19\n",
    "        :param num_fc: int, number of FC layers in the unit, default=2\n",
    "        :param pool_size: int, size of the unit's maxpooling layer, default=7\n",
    "        :param pool_stride: int, stride of the unit's maxpooling layer, default=7\n",
    "        :param weight_path: string, path to the file with model weights\n",
    "        \"\"\"\n",
    "        super(ExplaiNN, self).__init__()\n",
    "\n",
    "        self._options = {\n",
    "            \"num_cnns\": num_cnns,\n",
    "            \"input_length\": input_length,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"filter_size\": filter_size,\n",
    "            \"num_fc\": num_fc,\n",
    "            \"pool_size\": pool_size,\n",
    "            \"pool_stride\": pool_stride,\n",
    "            \"weight_path\": weight_path\n",
    "        }\n",
    "\n",
    "        if num_fc == 0:\n",
    "            self.linears = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=4 * num_cnns, out_channels=1 * num_cnns, kernel_size=filter_size,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(num_cnns),\n",
    "                ExpActivation(),\n",
    "                nn.MaxPool1d(input_length - (filter_size-1)),\n",
    "                nn.Flatten())\n",
    "        elif num_fc == 1:\n",
    "            self.linears = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=4 * num_cnns, out_channels=1 * num_cnns, kernel_size=filter_size,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(num_cnns),\n",
    "                ExpActivation(),\n",
    "                nn.MaxPool1d(pool_size, pool_stride),\n",
    "                nn.Flatten(),\n",
    "                Unsqueeze(),\n",
    "                nn.Conv1d(in_channels=int(((input_length - (filter_size-1)) - (pool_size-1)-1)/pool_stride + 1) * num_cnns,\n",
    "                          out_channels=1 * num_cnns, kernel_size=1,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(1 * num_cnns, 1e-05, 0.1, True),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten())\n",
    "        elif num_fc == 2:\n",
    "            self.linears = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=4 * num_cnns, out_channels=1 * num_cnns, kernel_size=filter_size,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(num_cnns),\n",
    "                ExpActivation(),\n",
    "                nn.MaxPool1d(pool_size, pool_stride),\n",
    "                nn.Flatten(),\n",
    "                Unsqueeze(),\n",
    "                nn.Conv1d(in_channels=int(((input_length - (filter_size-1)) - (pool_size-1)-1)/pool_stride + 1) * num_cnns,\n",
    "                          out_channels=100 * num_cnns, kernel_size=1,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(100 * num_cnns, 1e-05, 0.1, True),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Conv1d(in_channels=100 * num_cnns,\n",
    "                          out_channels=1 * num_cnns, kernel_size=1,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(1 * num_cnns, 1e-05, 0.1, True),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten())\n",
    "        else:\n",
    "            self.linears = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=4 * num_cnns, out_channels=1 * num_cnns, kernel_size=filter_size,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(num_cnns),\n",
    "                ExpActivation(),\n",
    "                nn.MaxPool1d(pool_size, pool_stride),\n",
    "                nn.Flatten(),\n",
    "                Unsqueeze(),\n",
    "                nn.Conv1d(in_channels=int(((input_length - (filter_size-1)) - (pool_size-1)-1)/pool_stride + 1) * num_cnns,\n",
    "                          out_channels=100 * num_cnns, kernel_size=1,\n",
    "                          groups=num_cnns),\n",
    "                nn.BatchNorm1d(100 * num_cnns, 1e-05, 0.1, True),\n",
    "                nn.ReLU())\n",
    "\n",
    "            self.linears_bg = nn.ModuleList([nn.Sequential(nn.Dropout(0.3),\n",
    "                                                           nn.Conv1d(in_channels=100 * num_cnns,\n",
    "                                                                     out_channels=100 * num_cnns, kernel_size=1,\n",
    "                                                                     groups=num_cnns),\n",
    "                                                           nn.BatchNorm1d(100 * num_cnns, 1e-05, 0.1, True),\n",
    "                                                           nn.ReLU()) for i in range(num_fc - 2)])\n",
    "\n",
    "            self.last_linear = nn.Sequential(nn.Dropout(0.3),\n",
    "                                             nn.Conv1d(in_channels=100 * num_cnns, out_channels=1 * num_cnns,\n",
    "                                                       kernel_size=1,\n",
    "                                                       groups=num_cnns),\n",
    "                                             nn.BatchNorm1d(1 * num_cnns, 1e-05, 0.1, True),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Flatten())\n",
    "\n",
    "        self.final = nn.Linear(num_cnns, num_classes)\n",
    "\n",
    "        if weight_path:\n",
    "            self.load_state_dict(torch.load(weight_path))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1, self._options[\"num_cnns\"], 1)\n",
    "        if self._options[\"num_fc\"] <= 2:\n",
    "            outs = self.linears(x)\n",
    "        else:\n",
    "            outs = self.linears(x)\n",
    "            for i in range(len(self.linears_bg)):\n",
    "                outs = self.linears_bg[i](outs)\n",
    "            outs = self.last_linear(outs)\n",
    "        out = self.final(outs)\n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
