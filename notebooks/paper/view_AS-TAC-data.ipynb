{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from explainn import tools\n",
    "from explainn import networks\n",
    "from explainn import train\n",
    "from explainn import test\n",
    "from explainn import interpretation\n",
    "from explainn import utils\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from explainn.train.train import train_explainn\n",
    "from explainn.utils.tools import dna_one_hot\n",
    "from explainn.models.networks import ExplaiNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the tsv file\n",
    "df = pd.read_csv('C:/Users/aslak/Master/Github_first/SCRATCH/AS-TAC/AS-TAC_1000bp.tsv', sep='\\t', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0                                                  1   2   3   \\\n",
      "2  1:385601-386600  GGGCATGTTGAGATAAATGTACTAACCGGGAGGGTTGAATGATGTA...   0   0   \n",
      "3  1:386201-387200  GATTGGATAACTAGGATGCTGCTGGTAGAGTAGCTAGCTAGCTTAC...   0   0   \n",
      "4  1:386401-387400  GATGCTGCTGGTAGAGTAGCTAGCTAGCTTCCTAGCTGTACCGACT...   0   0   \n",
      "5  1:386601-387600  TTACCTAGCTGTACCGACTAGCTAGGATAACTAGGGTGCTGCTGGT...   0   0   \n",
      "6  1:395601-396600  AGTTATTGATGATCTATTTCGTTGTCTTATGTTTATGTCCTTTTAA...   0   1   \n",
      "\n",
      "   4   5   6   7   8   9   ...  55  56  57  58  59  60  61  62  63  64  \n",
      "2   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "3   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "4   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "5   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "6   0   0   0   1   0   0  ...   0   0   1   0   0   1   0   0   0   0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "Shape of the df: (1638680, 65)\n"
     ]
    }
   ],
   "source": [
    "# print the head of the df second column\n",
    "print(df[2:].head())\n",
    "print(f\"Shape of the df: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences that contain at least one 'N': 1638603\n",
      "Number of sequences that are not of length 1000: 0\n",
      "Number of sequences that are good: 1638680\n",
      "Fraction of sequences that are good: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# count the number of sequences containing at least one 'N'\n",
    "count_N = df[1].str.contains('A').sum()\n",
    "\n",
    "# count the number of sequences not of length 1000\n",
    "count_not_1000 = (df[1].str.len() < 1000).sum()\n",
    "good_lines = (df[1].str.len() == 1000) & (~df[1].str.contains('N'))\n",
    "print(f\"Number of sequences that contain at least one 'N': {count_N}\")\n",
    "print(f\"Number of sequences that are not of length 1000: {count_not_1000}\")\n",
    "print(f\"Number of sequences that are good: {good_lines.sum()}\")\n",
    "print(f\"Fraction of sequences that are good: {good_lines.sum()/df.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3981       TCTCTGTCTGTCTCGCTCTCTGTCTGTCTGTCTCGCTCTCTGTCTG...\n",
      "286411     TCTCTCTCTCTGTGTCTCTCTCTCTCTGTGTCTCTGTGTGTGTCTC...\n",
      "747627     CTGTCTCTGTTTCTCTGTCTGTCTCTGTCTGTCTCTGTTTCTCTGT...\n",
      "1525743    TCGCTCTGCGTGTGGCGCTCTCTCGCTCTGCGTGTGGCGCTCTCGC...\n",
      "1525744    CTCTGCGTGCGTGTGGCGCTCTCTCTCTCGCTCTGCGTGCGTGTGG...\n",
      "                                 ...                        \n",
      "1627339    TGTGTGTGTGTGTGTGTGTGTGTGTTGTCGGTGTGTGTGTGTGTGT...\n",
      "1627340    GTGTGTGTGTTGTCGGTGTGTGTGTGTGTGTGTGTTGTCGGTGTGT...\n",
      "1627341    GGTGTGTGTGTGTGTGTGTGTTGTCGGTGTGTGTGTGTGTGTGTTG...\n",
      "1631206    TCTCTCTCTGTGTCTCTCTCTCTCTCTGTGTGTCTCTCTCTCTGTC...\n",
      "1631231    CTCTCTGTGTGTGTGTGTGTCTGTCTGTCTCTCTCTCTGTGTGTGT...\n",
      "Name: 1, Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print the sequences that does not contain an 'A'\n",
    "print(df[1][~df[1].str.contains('A')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          1:374401-375400\n",
      "1                          1:374601-375600\n",
      "2                          1:385601-386600\n",
      "3                          1:386201-387200\n",
      "4                          1:386401-387400\n",
      "                        ...               \n",
      "1638675    CAJNNT020004222.1:229401-230400\n",
      "1638676    CAJNNT020004222.1:229601-230600\n",
      "1638677    CAJNNT020004222.1:229801-230800\n",
      "1638678    CAJNNT020004222.1:230001-231000\n",
      "1638679    CAJNNT020004222.1:230201-231200\n",
      "Name: 0, Length: 1638680, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print rownames of test_feat\n",
    "print(df[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: 12, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a .h5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make a subset of df with only 100 rows\n",
    "df = df.iloc[:100, :]\n",
    "\n",
    "# load target_labels\n",
    "with open(\"../../dna-sequence-models/downloads/bed_list.txt\", 'r') as f:\n",
    "    labels = f.read().splitlines()\n",
    "\n",
    "# Remove \"AS-TAC-peaks/AtlanticSalmon_ATAC_\" and \".mLb.clN_peaks.narrowPeak\" from the strings in labels list\n",
    "labels = [label.replace(\"AS-TAC-peaks/AtlanticSalmon_ATAC_\", \"\").replace(\".mLb.clN_peaks.narrowPeak\", \"\") for label in labels]\n",
    "\n",
    "# remove chrom ranges if there are 65 columns\n",
    "if df.shape[1] == 65:\n",
    "    df = df.drop(0, axis=1)\n",
    "# separate sequences and binary features\n",
    "seqs = df.iloc[:, 0]\n",
    "features = df.iloc[:, 1:]\n",
    "\n",
    "# one hot encode sequences\n",
    "seqs_one_hot = np.array([dna_one_hot(str(seq)) for seq in seqs])\n",
    "seqs = seqs.apply(lambda x: pd.Series(list(x)))\n",
    "\n",
    "# split data into train, test, valid\n",
    "train_seq, test_seq, train_feat, test_feat = train_test_split(seqs_one_hot, features, test_size=0.15, random_state=42)\n",
    "train_seq, valid_seq, train_feat, valid_feat = train_test_split(train_seq, train_feat, test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create .h5 file\n",
    "with h5py.File('AS-TAC.h5', 'w') as hf:\n",
    "    hf.create_dataset('train_in', data=train_seq)\n",
    "    hf.create_dataset('valid_in', data=valid_seq)\n",
    "    hf.create_dataset('test_in', data=test_seq)\n",
    "    hf.create_dataset('train_out', data=train_feat)\n",
    "    hf.create_dataset('valid_out', data=valid_feat)\n",
    "    hf.create_dataset('test_out', data=test_feat)\n",
    "    hf.create_dataset('target_labels', data=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
