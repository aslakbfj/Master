{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from explainn import tools\n",
    "from explainn import networks\n",
    "from explainn import train\n",
    "from explainn import test\n",
    "from explainn import interpretation\n",
    "from explainn import utils\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from explainn.train.train import train_explainn\n",
    "from explainn.utils.tools import dna_one_hot\n",
    "from explainn.models.networks import ExplaiNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the tsv file\n",
    "df = pd.read_csv('C:/Users/aslak/Master/Github_first/SCRATCH/AS-TAC/AS-TAC_1000bp.tsv', sep='\\t', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0                                                  1   2   3   \\\n",
      "0  1:374401-375400  CTGGTCAGGACGTGACAGTACCCCCCCAAAGGTGCAGACCCCGGAT...   0   0   \n",
      "1  1:374601-375600  GTGGACTCTGCTCCACCCTCGACGTCGCCCACTTAGGTGGTGCCCC...   0   0   \n",
      "2  1:385601-386600  GGGCATGTTGAGATAAATGTACTAACCGGGAGGGTTGAATGATGTA...   0   0   \n",
      "3  1:386201-387200  GATTGGATAACTAGGATGCTGCTGGTAGAGTAGCTAGCTAGCTTAC...   0   0   \n",
      "4  1:386401-387400  GATGCTGCTGGTAGAGTAGCTAGCTAGCTTCCTAGCTGTACCGACT...   0   0   \n",
      "\n",
      "   4   5   6   7   8   9   ...  55  56  57  58  59  60  61  62  63  64  \n",
      "0   0   0   0   0   0   0  ...   1   0   0   0   0   0   0   0   0   0  \n",
      "1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "2   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "3   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "4   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "Shape of the df: (1638680, 65)\n"
     ]
    }
   ],
   "source": [
    "# print the head of the df\n",
    "print(df.head())\n",
    "print(f\"Shape of the df: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows that starts with 21: 36084\n",
      "Number of rows that starts with 25: 34250\n",
      "Number of rows that starts with 21 or 25: 70334\n",
      "Portion of the data that starts with 21 or 25: 0.042921131642541556\n"
     ]
    }
   ],
   "source": [
    "#print how many rows that starts with \"21\" in the first column\n",
    "print(f\"Number of rows that starts with 21: {df[df[0].str.startswith('21')].shape[0]}\")\n",
    "# print how many rows that starts with \"25\" in the first column\n",
    "print(f\"Number of rows that starts with 25: {df[df[0].str.startswith('25')].shape[0]}\")\n",
    "# print how many rows that starts with \"21\" or \"25\" in the first column\n",
    "print(f\"Number of rows that starts with 21 or 25: {df[df[0].str.startswith('21') | df[0].str.startswith('25')].shape[0]}\")\n",
    "# print what portion of the data that starts with \"21\" or \"25\"\n",
    "print(f\"Portion of the data that starts with 21 or 25: {(df[df[0].str.startswith('21')].shape[0] + df[df[0].str.startswith('25')].shape[0])/df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # make a subset of the data that starts with \"21\" or \"25\"\n",
    "# df_21_25 = df[df[0].str.startswith('21') | df[0].str.startswith('25')]\n",
    "# # make a subset of the rest of the data\n",
    "# df_excluded_21_25 = df[~(df[0].str.startswith('21') | df[0].str.startswith('25'))]\n",
    "\n",
    "# # remove chrom ranges if there are 65 columns\n",
    "# if df_21_25.shape[1] == 65:\n",
    "#     df_21_25 = df_21_25.drop(0, axis=1)\n",
    "# # remove chrom ranges if there are 65 columns\n",
    "# if df_excluded_21_25.shape[1] == 65:\n",
    "#     df_excluded_21_25 = df_excluded_21_25.drop(0, axis=1)\n",
    "\n",
    "\n",
    "# Make a new df_21_25_added from where you add a random 5 % of the rows of df_excluded_21_25 to df_21_25, and remove those rows from df_excluded_21_25 to a new df with _removed. Dataframes does not have attribute called append\n",
    "sample = df_excluded_21_25.sample(frac=0.05)\n",
    "df_21_25_10 = pd.concat([df_21_25, sample])\n",
    "df_excluded_21_25_10 = df_excluded_21_25.drop(sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_21_25_added: (148751, 64)\n",
      "Shape of df_excluded_21_25_removed: (1489929, 64)\n",
      "Shape of df: (1638680, 65)\n",
      "Shape of df_21_25_added + df_excluded_21_25_removed: 1638680\n"
     ]
    }
   ],
   "source": [
    "#check that the row of the two last dataframes add up to the original\n",
    "print(f\"Shape of df_21_25_added: {df_21_25_10.shape}\")\n",
    "print(f\"Shape of df_excluded_21_25_removed: {df_excluded_21_25_10.shape}\")\n",
    "print(f\"Shape of df: {df.shape}\")\n",
    "print(f\"Shape of df_21_25_added + df_excluded_21_25_removed: {df_21_25_10.shape[0] + df_excluded_21_25_10.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences that contain at least one 'N': 0\n",
      "Number of sequences that are not of length 1000: 0\n",
      "Number of sequences that are good: 1638680\n",
      "Fraction of sequences that are good: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# count the number of sequences containing at least one 'N'\n",
    "count_N = df[1].str.contains('N').sum()\n",
    "\n",
    "# count the number of sequences not of length 1000\n",
    "count_not_1000 = (df[1].str.len() < 1000).sum()\n",
    "good_lines = (df[1].str.len() == 1000) & (~df[1].str.contains('N'))\n",
    "print(f\"Number of sequences that contain at least one 'N': {count_N}\")\n",
    "print(f\"Number of sequences that are not of length 1000: {count_not_1000}\")\n",
    "print(f\"Number of sequences that are good: {good_lines.sum()}\")\n",
    "print(f\"Fraction of sequences that are good: {good_lines.sum()/df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3981       TCTCTGTCTGTCTCGCTCTCTGTCTGTCTGTCTCGCTCTCTGTCTG...\n",
      "286411     TCTCTCTCTCTGTGTCTCTCTCTCTCTGTGTCTCTGTGTGTGTCTC...\n",
      "747627     CTGTCTCTGTTTCTCTGTCTGTCTCTGTCTGTCTCTGTTTCTCTGT...\n",
      "1525743    TCGCTCTGCGTGTGGCGCTCTCTCGCTCTGCGTGTGGCGCTCTCGC...\n",
      "1525744    CTCTGCGTGCGTGTGGCGCTCTCTCTCTCGCTCTGCGTGCGTGTGG...\n",
      "                                 ...                        \n",
      "1627339    TGTGTGTGTGTGTGTGTGTGTGTGTTGTCGGTGTGTGTGTGTGTGT...\n",
      "1627340    GTGTGTGTGTTGTCGGTGTGTGTGTGTGTGTGTGTTGTCGGTGTGT...\n",
      "1627341    GGTGTGTGTGTGTGTGTGTGTTGTCGGTGTGTGTGTGTGTGTGTTG...\n",
      "1631206    TCTCTCTCTGTGTCTCTCTCTCTCTCTGTGTGTCTCTCTCTCTGTC...\n",
      "1631231    CTCTCTGTGTGTGTGTGTGTCTGTCTGTCTCTCTCTCTGTGTGTGT...\n",
      "Name: 1, Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print the sequences that does not contain an 'A'\n",
    "print(df[1][~df[1].str.contains('A')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          1:374401-375400\n",
      "1                          1:374601-375600\n",
      "2                          1:385601-386600\n",
      "3                          1:386201-387200\n",
      "4                          1:386401-387400\n",
      "                        ...               \n",
      "1638675    CAJNNT020004222.1:229401-230400\n",
      "1638676    CAJNNT020004222.1:229601-230600\n",
      "1638677    CAJNNT020004222.1:229801-230800\n",
      "1638678    CAJNNT020004222.1:230001-231000\n",
      "1638679    CAJNNT020004222.1:230201-231200\n",
      "Name: 0, Length: 1638680, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print rownames of test_feat\n",
    "print(df[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a .h5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make a subset of df with only 50 000 random rows\n",
    "df = df.sample(n=50000, random_state=42)\n",
    "\n",
    "# load target_labels\n",
    "with open(\"../../dna-sequence-models/downloads/bed_list.txt\", 'r') as f:\n",
    "    labels = f.read().splitlines()\n",
    "\n",
    "# Remove \"AS-TAC-peaks/AtlanticSalmon_ATAC_\" and \".mLb.clN_peaks.narrowPeak\" from the strings in labels list\n",
    "labels = [label.replace(\"AS-TAC-peaks/AtlanticSalmon_ATAC_\", \"\").replace(\".mLb.clN_peaks.narrowPeak\", \"\") for label in labels]\n",
    "\n",
    "# remove chrom ranges if chrom column is there, i.e. if column 1 has a \":\" in it\n",
    "if df[0].str.contains(\":\").sum() > 0:\n",
    "    df = df.drop(0, axis=1)\n",
    "    \n",
    "# separate sequences and binary features\n",
    "seqs = df.iloc[:, 0]\n",
    "features = df.iloc[:, 1:]\n",
    "\n",
    "# one hot encode sequences\n",
    "seqs_one_hot = np.array([dna_one_hot(str(seq)) for seq in seqs])\n",
    "seqs = seqs.apply(lambda x: pd.Series(list(x)))\n",
    "\n",
    "# split data into train, test, valid\n",
    "train_seq, test_seq, train_feat, test_feat = train_test_split(seqs_one_hot, features, test_size=0.20, random_state=42)\n",
    "train_seq, valid_seq, train_feat, valid_feat = train_test_split(train_seq, train_feat, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m########### MAKE A 5 % SPLIT WITH 21 25 SEPARATED ###########\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_21_25 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m21\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m df[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# make a subset of the rest of the data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df_excluded_21_25 \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39m(df[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m21\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m df[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "########### MAKE A 5 % SPLIT WITH 21 25 SEPARATED ###########\n",
    "df_21_25 = df[df[0].str.startswith('21') | df[0].str.startswith('25')]\n",
    "# make a subset of the rest of the data\n",
    "df_excluded_21_25 = df[~(df[0].str.startswith('21') | df[0].str.startswith('25'))]\n",
    "\n",
    "# remove chrom ranges if there are 65 columns\n",
    "if df_21_25.shape[1] == 65:\n",
    "    df_21_25 = df_21_25.drop(0, axis=1)\n",
    "# remove chrom ranges if there are 65 columns\n",
    "if df_excluded_21_25.shape[1] == 65:\n",
    "    df_excluded_21_25 = df_excluded_21_25.drop(0, axis=1)\n",
    "\n",
    "# separate sequences and binary features\n",
    "seqs_21_25 = df_21_25.iloc[:, 0]\n",
    "features_21_25 = df_21_25.iloc[:, 1:]\n",
    "seqs_excluded_21_25 = df_excluded_21_25.iloc[:, 0]\n",
    "features_excluded_21_25 = df_excluded_21_25.iloc[:, 1:]\n",
    "\n",
    "# one hot encode sequences\n",
    "seqs_21_25 = np.array([dna_one_hot(str(seq)) for seq in seqs_21_25])\n",
    "seqs_excluded_21_25 = np.array([dna_one_hot(str(seq)) for seq in seqs_excluded_21_25])\n",
    "\n",
    "# split data into train_21, test_21\n",
    "train_seq_21, test_seq_21, train_feat_21, test_feat_21 = train_test_split(seqs_excluded_21_25, features_excluded_21_25, test_size=0.05, random_state=42)\n",
    "valid_seq_21, valid_feat_21 = seqs_21_25, features_21_25\n",
    "\n",
    "# create .h5 file\n",
    "with h5py.File(args['output'] + \"AS-TAC_21_25_05.h5\", 'w') as hf:\n",
    "    hf.create_dataset('train_in', data=train_seq_21)\n",
    "    hf.create_dataset('valid_in', data=valid_seq_21)\n",
    "    hf.create_dataset('test_in', data=test_seq_21)\n",
    "    hf.create_dataset('train_out', data=train_feat_21)\n",
    "    hf.create_dataset('valid_out', data=valid_feat_21)\n",
    "    hf.create_dataset('test_out', data=test_feat_21)\n",
    "    hf.create_dataset('target_labels', data=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create .h5 file\n",
    "with h5py.File('../../../SCRATCH/AS-TAC/AS-TAC_50K.h5', 'w') as hf:\n",
    "    hf.create_dataset('train_in', data=train_seq)\n",
    "    hf.create_dataset('valid_in', data=valid_seq)\n",
    "    hf.create_dataset('test_in', data=test_seq)\n",
    "    hf.create_dataset('train_out', data=train_feat)\n",
    "    hf.create_dataset('valid_out', data=valid_feat)\n",
    "    hf.create_dataset('test_out', data=test_feat)\n",
    "    hf.create_dataset('target_labels', data=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liver_Mature_Male_R1',\n",
       " 'MidSomitogenesis_R1',\n",
       " 'Muscle_Immature_Female_R3',\n",
       " 'Muscle_Mature_Male_R3',\n",
       " 'LateSomitogenesis_R3',\n",
       " 'Liver_Immature_Female_R1',\n",
       " 'Gonad_Immature_Female_R3',\n",
       " 'MidGastrulation_R3',\n",
       " 'MidGastrulation_R1',\n",
       " 'Muscle_Mature_Female_R3',\n",
       " 'LateSomitogenesis_R1',\n",
       " 'Brain_Immature_Male_R2',\n",
       " 'Gonad_Immature_Male_R1',\n",
       " 'Liver_Immature_Female_R2',\n",
       " 'LateBlastulation_R3',\n",
       " 'EarlySomitogenesis_R1',\n",
       " 'MidSomitogenesis_R3',\n",
       " 'Liver_Mature_Female_R3',\n",
       " 'Brain_Mature_Male_R1',\n",
       " 'Liver_Immature_Male_R3',\n",
       " 'Liver_Mature_Female_R2',\n",
       " 'Brain_Immature_Male_R3',\n",
       " 'Brain_Immature_Female_R3',\n",
       " 'Gonad_Immature_Female_R2',\n",
       " 'LateSomitogenesis_R2',\n",
       " 'Brain_Mature_Female_R2',\n",
       " 'Gonad_Mature_Female_R3',\n",
       " 'Brain_Mature_Male_R2',\n",
       " 'EarlySomitogenesis_R3',\n",
       " 'Brain_Immature_Male_R1',\n",
       " 'Liver_Mature_Male_R3',\n",
       " 'Muscle_Mature_Female_R2',\n",
       " 'Muscle_Immature_Female_R1',\n",
       " 'Brain_Immature_Female_R2',\n",
       " 'Brain_Mature_Male_R3',\n",
       " 'Liver_Immature_Male_R1',\n",
       " 'Muscle_Immature_Female_R2',\n",
       " 'MidGastrulation_R2',\n",
       " 'Gonad_Immature_Male_R3',\n",
       " 'MidSomitogenesis_R2',\n",
       " 'Brain_Immature_Female_R1',\n",
       " 'Liver_Immature_Male_R2',\n",
       " 'Brain_Mature_Female_R1',\n",
       " 'LateBlastulation_R2',\n",
       " 'Liver_Mature_Male_R2',\n",
       " 'Muscle_Mature_Male_R1',\n",
       " 'Gonad_Mature_Female_R2',\n",
       " 'Gonad_Immature_Female_R1',\n",
       " 'Gonad_Mature_Male_R2',\n",
       " 'Brain_Mature_Female_R3',\n",
       " 'Muscle_Immature_Male_R2',\n",
       " 'Muscle_Mature_Male_R2',\n",
       " 'Muscle_Immature_Male_R1',\n",
       " 'Gonad_Mature_Male_R1',\n",
       " 'Liver_Immature_Female_R3',\n",
       " 'Gonad_Mature_Female_R1',\n",
       " 'LateBlastulation_R1',\n",
       " 'Muscle_Mature_Female_R1',\n",
       " 'Gonad_Immature_Male_R2',\n",
       " 'Muscle_Immature_Male_R3',\n",
       " 'Liver_Mature_Female_R1',\n",
       " 'Gonad_Mature_Male_R3',\n",
       " 'EarlySomitogenesis_R2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
